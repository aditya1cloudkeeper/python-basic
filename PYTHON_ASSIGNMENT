# #1ST QUESTION 1ST  PART
        
        # import re
        # def validateip(ip):
        #     regex = "^((25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])\.){3}(25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])$"
            
        #     if not re.match(regex,ip):
        #         return "Not a valid IP address"
        
            # dot = list(map(int, ip.split('.')))
            
        #     if dot[0] == 10:
        #         return False, "It is a private IP"
        #     elif dot[0] == 172 and 16 <= dot[1] <=31:
        #         return False, "It is a private IP"
        #     elif dot[0] == 192 and dot[1] == 168:
        #         return False, "It is a private IP"
            
        #     return "Valid IP Address"
            
        # ip = "192.168.255.255"
        # print(validateip(ip))

# #1ST QUESTION 2ND  PART
        
        # def validatemail(email):
         
        #     if not email.endswith('@gmail.com'):
        #         return "It should contain @gmail.com at the end"
            
        #     parts = email.split('@')
        #     if len(parts) != 2:
        #         return "@ can be only once"
            
        #     local_part = parts[0]
        #     if len(local_part) == 0:
        #         return "Enter the username"
            
           
        #     if not re.fullmatch(r'^[a-z0-9._-]+$', local_part):
        #         return False, "Username should contain only lowercase letters , numbers and permitted symbols."
            
        #     return True, "Valid Gmail address."
        
        # email = "a@gmailcom"
        # print(validatemail(email))


# 2nd Question 

        # import random
        # import string


        # def password():

        #     uppercase = string.ascii_uppercase
        #     lowercase = string.ascii_lowercase
        #     numbers = string.digits
        #     specials = "!@#$%&*"


        #     required_characters = [
        #         random.choice(uppercase),random.choice(lowercase),random.choice(numbers),random.choice(specials),
        #         random.choice(uppercase),random.choice(lowercase),random.choice(numbers),random.choice(specials),
        #         random.choice(uppercase),random.choice(lowercase),random.choice(numbers),random.choice(specials),
        #         random.choice(uppercase),random.choice(lowercase),random.choice(numbers),random.choice(specials),
        #     ]

        #     random.shuffle(required_characters )

        #     return ''.join(required_characters )


        # print( password())

# 3RD QUESTION


        # import requests
        # import time
        # import logging

        # def setup_logging():

        #     logging.basicConfig(
        #         filename='uptime_monitor.log',  # Log file name
        #         level=logging.INFO,             # Log INFO and above (INFO, ERROR, etc.)
        #         format='%(asctime)s - %(levelname)s - %(message)s'
        #     )

        # def check_url(url):

        #     try:
        #         response = requests.get(url, timeout=5)  # 5-second timeout for the request
        #         return response.status_code, response.reason
        #     except Exception as error:
        #         return None, str(error)

        # def monitor_urls(urls, base_interval=10):

        #     # Track consecutive error counts for each URL.
        #     error_counts = {url: 0 for url in urls}
        
        #     # Infinite loop: keep checking the URLs at regular intervals.
        #     while True:
        #         # Determine the maximum error count among all URLs (used for backoff timing).
        #         max_error_count = 0
                
        #         # Check each URL one by one.
        #         for url in urls:
        #             print(f"Checking URL: {url}")
        #             logging.info(f"Checking URL: {url}")
                
        #             status_code, message = check_url(url)
                
        #             # If we didn't get a valid status code (e.g., due to a timeout or connection error)
        #             if status_code is None:
        #                 error_msg = f"Error checking {url}: {message}"
        #                 print(error_msg)
        #                 logging.error(error_msg)
        #                 error_counts[url] += 1  # Increase error count
        #             else:
        #                 # Format the status code and message nicely.
        #                 full_status = f"{status_code} {message}"
        #                 print(f"Status Code: {full_status}")
        #                 logging.info(f"URL: {url} returned {full_status}")
                        
        #                 # Check if the status indicates an error (client error 4xx or server error 5xx)
        #                 if 400 <= status_code < 600:
        #                     if 400 <= status_code < 500:
        #                         alert = f"ALERT: 4xx error encountered for URL: {url}"
        #                     else:
        #                         alert = f"ALERT: 5xx error encountered for URL: {url}"
        #                     print(alert)
        #                     logging.error(alert)
        #                     error_counts[url] += 1
        #                 else:
        #                     print("The website is UP and running.\n")
        #                     error_counts[url] = 0  # Reset error count if the check was successful

        #             # Update the maximum error count seen (for calculating backoff)
        #             max_error_count = max(max_error_count, error_counts[url])
        #             print()  # Blank line for better readability

        #         # Use exponential backoff: wait longer if there have been several consecutive errors.
        #         wait_time = base_interval * (2 ** max_error_count)
        #         print(f"Waiting for {wait_time} seconds before the next check...\n")
        #         time.sleep(wait_time)

        # if __name__ == "__main__":
        #     setup_logging()  # Initialize the log file
    
        #       # List of URLs to be monitored.
        #     url_list = [
        #         "http://www.example.com/nonexistentpage",  # Expected: 4xx error
        #         "http://httpstat.us/404",                   # Expected: 4xx error
        #         "http://httpstat.us/500",                   # Expected: 5xx error
        #         "https://www.google.com/"                   # Expected: 200 OK
        #     ]
    
        #     # Start the monitoring loop 
        #     monitor_urls(url_list, base_interval=10)


# 4TH QUESTION

        # import subprocess
        # import logging
        # import sys

        # # Set up logging to record all activity in a file.
        # logging.basicConfig(
        #     filename='package_update.log',      # Log file to save the update process details
        #     level=logging.INFO,                 # Record info-level messages and above (INFO, ERROR, etc.)
        #     format='%(asctime)s - %(levelname)s - %(message)s'
        # )


        # def run_shell_command(command):
        #     """
        #     Run a command in the shell and return its output.
        #     If the command fails, log the error and return None.
        #     """
        #     try:
        #         result = subprocess.run(
        #             command,
        #             shell=True,
        #             check=True,  # Raise an exception if the command fails
        #             stdout=subprocess.PIPE,
        #             stderr=subprocess.PIPE,
        #             text=True
        #         )
        #         return result.stdout
        #     except subprocess.CalledProcessError as error:
        #         logging.error(f"Command failed: {command}\nError: {error.stderr}")
        #         return None


        # def refresh_package_list():
        #     """
        #     Refresh the package list to get the latest available updates.
        #     This is like doing 'sudo apt update' in the terminal.
        #     """
        #     print("Refreshing the package list (this may prompt for your sudo password)...")
        #     logging.info("Refreshing package list with 'apt update'")
        #     output = run_shell_command("sudo apt update")
        #     if output is None:
        #         print("Uh-oh! The package list couldn't be updated. Please check your connection or permissions.")
        #         sys.exit(1)
        #     print("Package list refreshed successfully!")
        #     logging.info("Package list refreshed.")


        # def get_upgradable_packages():
        #     """
        #     Retrieve the list of packages that have updates available.
        #     It uses 'apt list --upgradable' and then extracts the package names.
        #     Returns a list of package names.
        #     """
        #     print("Finding out which packages can be updated...")
        #     output = run_shell_command("apt list --upgradable")
        #     if output is None:
        #         print("Error: Unable to retrieve the list of upgradable packages.")
        #         sys.exit(1)

        #     package_list = []
        #     lines = output.splitlines()
        #     # The first line is usually a header ("Listing...")
        #     for line in lines:
        #         if line.startswith("Listing..."):
        #             continue
        #         try:
        #             # Example line: "bash/now 5.0-6ubuntu1.1 amd64 [upgradable from: 5.0-6ubuntu1]"
        #             package_field = line.split()[0]     # "bash/now"
        #             package_name = package_field.split('/')[0]  # "bash"
        #             package_list.append(package_name)
        #         except Exception as error:
        #             logging.error(f"Could not parse line: {line}. Error: {error}")

        #     return package_list


        # def update_specific_package(package_name):
        #     """
        #     Update a specific package using apt-get install.
        #     This is equivalent to running 'sudo apt-get install -y <package_name>'.
        #     """
        #     print(f"Starting update for package: {package_name}")
        #     logging.info(f"Updating package: {package_name}")
        #     command = f"sudo apt-get install -y {package_name}"
        #     output = run_shell_command(command)
        #     if output is None:
        #         error_message = f"Oops! Updating package {package_name} failed."
        #         print(error_message)
        #         logging.error(error_message)
        #     else:
        #         print(f"Package {package_name} updated successfully!")
        #         logging.info(f"Package {package_name} updated successfully.")


        # def update_all_packages():
        #     """
        #     Update all packages that have updates available.
        #     This runs 'sudo apt-get upgrade -y' to update every package.
        #     """
        #     print("Updating ALL packages. Please be patient; this might take a while...")
        #     logging.info("Updating all packages with 'sudo apt-get upgrade -y'")
        #     command = "sudo apt-get upgrade -y"
        #     output = run_shell_command(command)
        #     if output is None:
        #         error_message = "Failed to update all packages."
        #         print(error_message)
        #         logging.error(error_message)
        #     else:
        #         print("All packages have been updated successfully!")
        #         logging.info("All packages updated successfully.")


        # def main():
        #     # First, update the package list to ensure we have the latest information.
        #     refresh_package_list()

        #     # Next, get the list of packages that can be updated.
        #     packages = get_upgradable_packages()

        #     if not packages:
        #         print("Great news! No updates are available at this time.")
        #         return

        #     # Show the list of packages along with an index for easy selection.
        #     print("\nThe following packages have updates available:")
        #     for index, pkg in enumerate(packages):
        #         print(f"  [{index}] {pkg}")

        #     # Ask the user whether they want to update all packages or choose specific ones.
        #     print("\nWould you like to update ALL packages, or just one (or more) of them?")
        #     print("Type 'all' to update everything, or enter the index number(s) of the package(s) you want to update.")
        #     user_choice = input("Your choice (e.g., all OR 0,2,3): ").strip().lower()

        #     if user_choice == "all":
        #         update_all_packages()
        #     else:
        #         # Handle the possibility of multiple indices (separated by commas)
        #         indices = user_choice.split(',')
        #         for index_str in indices:
        #             try:
        #                 index = int(index_str.strip())
        #                 if index < 0 or index >= len(packages):
        #                     print(f"Index {index} is out of range. Skipping.")
        #                     continue
        #                 package_name = packages[index]
        #                 update_specific_package(package_name)
        #             except ValueError:
        #                 print(f"Invalid input '{index_str}'. Please enter a number.")
        #                 continue

        #     print("\nUpdate process is complete. Check 'package_update.log' for more details.")


        # if __name__ == "__main__":
        #     main()

#5TH QUESTION


        # import os
        # import hashlib
        # import argparse
        # import shutil

        # def calculate_file_checksum(file_path, block_size=65536):
        #     """
        #     Calculate a SHA‑256 checksum for the file at 'file_path'.
        
        #     Reads the file in chunks (so large files are handled easily) and returns a 
        #     hexadecimal string of the checksum.
        #     """
        #     sha256 = hashlib.sha256()
        #     try:
        #         with open(file_path, 'rb') as f:
        #             while True:
        #                 chunk = f.read(block_size)
        #                 if not chunk:
        #                     break
        #                 sha256.update(chunk)
        #         return sha256.hexdigest()
        #     except Exception as error:
        #         print(f"Error reading '{file_path}': {error}")
        #         return None

        # def scan_directory(directory):
        #     """
        #     Walk through 'directory' (including subdirectories) and build a dictionary
        #     that maps each file's checksum to a list of file paths.
        
        #     This way, if two (or more) files have the same checksum, they are likely duplicates.
        #     """
        #     print("Scanning directory for files...")
        #     checksum_dict = {}
        #     for folder, _, files in os.walk(directory):
        #         for name in files:
        #             file_path = os.path.join(folder, name)
        #             print(f"  Processing: {file_path}")
        #             checksum = calculate_file_checksum(file_path)
        #             if checksum:
        #                 # If this checksum already exists, append the file path to the list.
        #                 if checksum in checksum_dict:
        #                     checksum_dict[checksum].append(file_path)
        #                 else:
        #                     checksum_dict[checksum] = [file_path]
        #     return checksum_dict

        # def display_duplicates(checksum_dict):
        #     """
        #     Look at the checksum dictionary and print groups of files that are duplicates.
        #     Only groups with more than one file are considered duplicates.
        #     Returns a new dictionary with just the duplicate groups.
        #     """
        #     duplicate_groups = {}
        #     group_number = 1
        #     for checksum, files in checksum_dict.items():
        #         if len(files) > 1:
        #             print(f"\nDuplicate Group {group_number}:")
        #             print(f"Checksum: {checksum}")
        #             for idx, file in enumerate(files):
        #                 print(f"  [{idx}] {file}")
        #             duplicate_groups[checksum] = files
        #             group_number += 1

        #     if not duplicate_groups:
        #         print("\nNo duplicate files found!")
        #     return duplicate_groups

        # def delete_duplicate_files(duplicate_groups):
        #     """
        #     For each group of duplicates, keep the first file and delete the others.
        #     """
        #     print("\nDeleting duplicate files (keeping one copy per group)...")
        #     for checksum, files in duplicate_groups.items():
        #         # Skip the first file (we keep it) and delete the rest.
        #         for file_path in files[1:]:
        #             try:
        #                 os.remove(file_path)
        #                 print(f"Deleted: {file_path}")
        #             except Exception as error:
        #                 print(f"Error deleting '{file_path}': {error}")

        # def move_duplicate_files(duplicate_groups, destination):
        #     """
        #     For each duplicate group, move all copies except the first one to the destination folder.
        
        #     If the destination folder does not exist, it will be created.
        #     If a file with the same name already exists in the destination, a new name is created.
        #     """
        #     if not os.path.exists(destination):
        #         os.makedirs(destination)
        #         print(f"Created destination folder: {destination}")

        #     print(f"\nMoving duplicate files to '{destination}' (keeping one copy per group)...")
        #     for checksum, files in duplicate_groups.items():
        #         for file_path in files[1:]:
        #             try:
        #                 base_name = os.path.basename(file_path)
        #                 target_path = os.path.join(destination, base_name)
        #                 # If the target file exists, append a counter.
        #                 counter = 1
        #                 while os.path.exists(target_path):
        #                     name, ext = os.path.splitext(base_name)
        #                     target_path = os.path.join(destination, f"{name}_{counter}{ext}")
        #                     counter += 1
        #                 shutil.move(file_path, target_path)
        #                 print(f"Moved: {file_path} -> {target_path}")
        #             except Exception as error:
        #                 print(f"Error moving '{file_path}': {error}")

        # def main():
        #     # Set up command-line argument parsing.
        #     parser = argparse.ArgumentParser(
        #         description="Find duplicate files in a directory and optionally delete or move them."
        #     )
        #     parser.add_argument("directory", help="The directory to scan for duplicate files")
        #     args = parser.parse_args()

        #     if not os.path.isdir(args.directory):
        #         print(f"Error: '{args.directory}' is not a valid directory.")
        #         return

        #     # Step 1: Scan the directory for files and compute checksums.
        #     checksums = scan_directory(args.directory)

        #     # Step 2: Display duplicate groups.
        #     duplicates = display_duplicates(checksums)
        #     if not duplicates:
        #         return  # Nothing to do if no duplicates are found.

        #     # Step 3: Ask the user what to do with duplicates.
        #     print("\nWhat would you like to do with these duplicates?")
        #     print("  [d] Delete duplicate files (keep one copy)")
        #     print("  [m] Move duplicate files to a folder")
        #     print("  [n] Do nothing and exit")
        #     action = input("Enter your choice (d/m/n): ").strip().lower()

        #     if action == 'd':
        #         answer = input("Are you sure you want to delete duplicate files? (yes/no): ").strip().lower()
        #         if answer == 'yes':
        #             delete_duplicate_files(duplicates)
        #             print("Deletion complete.")
        #         else:
        #             print("Deletion cancelled.")
        #     elif action == 'm':
        #         destination = input("Enter the destination folder to move duplicates into: ").strip()
        #         move_duplicate_files(duplicates, destination)
        #         print("Moving complete.")
        #     else:
        #         print("No changes made. Exiting.")

        # if __name__ == "__main__":
        #     main()


        # import csv
        # import sys

        # def read_csv_file(file_path):

        #     rows = []
        #     try:
        #         with open(file_path, mode='r', newline='', encoding='utf-8') as csvfile:
        #             csv_reader = csv.reader(csvfile)
        #             for row in csv_reader:
        #                 rows.append(row)
        #     except Exception as error:
        #         print(f"Oops! Could not read file '{file_path}'. Error: {error}")
        #         sys.exit(1)
        #     return rows

        # def get_column_widths(rows):

        #     if not rows:
        #         return []
        
        #     num_columns = len(rows[0])
        #     widths = [0] * num_columns

        #     for row in rows:
        #         for i in range(num_columns):
        #             cell_text = str(row[i])
        #             widths[i] = max(widths[i], len(cell_text))
        #     return widths

        # def create_border_line(widths):

        #     segments = []
        #     for width in widths:
        #         # Add 2 extra characters for padding (one space each side)
        #         segments.append('-' * (width + 2))
        #     border = '+' + '+'.join(segments) + '+'
        #     return border

        # def print_table(rows):

        #     if not rows:
        #         print("No data found in the CSV file!")
        #         return

        #     # Determine how wide each column should be
        #     column_widths = get_column_widths(rows)
        #     horizontal_border = create_border_line(column_widths)

        #     print("Here is your table:")
        #     print(horizontal_border)

        #     # Print header row with left-justified cells
        #     header = rows[0]
        #     header_cells = []
        #     for i, cell in enumerate(header):
        #         # Pad the cell with spaces: one on each side, and left-justify within the column width.
        #         header_cells.append(" " + cell.ljust(column_widths[i]) + " ")
        #     header_line = "|" + "|".join(header_cells) + "|"
        #     print(header_line)

        #     # Print a border after the header row
        #     print(horizontal_border)

        #     # Print the remaining data rows in a similar manner
        #     for row in rows[1:]:
        #         row_cells = []
        #         for i, cell in enumerate(row):
        #             row_cells.append(" " + cell.ljust(column_widths[i]) + " ")
        #         row_line = "|" + "|".join(row_cells) + "|"
        #         print(row_line)

        #     # Print the bottom border to complete the table
        #     print(horizontal_border)

        # def main():
        #     # Ensure the user provided the path to the CSV file.
        #     if len(sys.argv) < 2:
        #         print("Usage: python human_friendly_table.py <path_to_csv_file>")
        #         sys.exit(1)
        
        #     file_path = sys.argv[1]
        #     # Read the CSV file.
        #     csv_rows = read_csv_file(file_path)
        #     # Display the table.
        #     print_table(csv_rows)

        # if __name__ == "__main__":
        #     main()
